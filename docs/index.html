<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Home</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Home</h1>

    



    


    <h3> </h3>










    




    <section>
        <article><h1>azbak</h1><p>Command-line utility and Node.js module to backup a file or a stream to Azure Blob Storage.</p>
<p>Features:</p>
<ul>
<li>Fully stream-based</li>
<li>The CLI supports piping input from a stream or reading from a file on disk</li>
<li>Automatically chunks files/streams bigger than the maximum blob size (~4.8 TB) into multiple blobs</li>
<li>Supports SAS Tokens</li>
<li>Cross-platform</li>
<li>Small memory footprint</li>
</ul>
<h1>Command-line tool</h1><h2>Installation</h2><p>azbak requires Node.js version 4.0 or higher and NPM.</p>
<p>You can install the application from NPM:</p>
<pre class="prettyprint source lang-sh"><code># Depending on your system, you may need to run this as root or add &quot;sudo&quot;
$ npm install --global azbak</code></pre><h2>Usage</h2><p>Command reference:</p>
<pre class="prettyprint source lang-sh"><code>azbak [options] &lt;input> &lt;destinationPath></code></pre><h3>Authentication</h3><p>You need to authenticate against Azure Blob Storage using a storage account name and an access key. azbak supports passing these values in the same way as the official Azure CLI, using environmental variables <strong><code>AZURE_STORAGE_ACCOUNT</code></strong> and <strong><code>AZURE_STORAGE_ACCESS_KEY</code></strong>.</p>
<p>Alternatively, you can authenticate using <a href="https://docs.microsoft.com/en-us/azure/storage/storage-dotnet-shared-access-signature-part-1">Shared Access Signature (SAS) tokens</a>, which are limited in time and scope, and are a safer alternative for scripts, cron jobs, etc. To use SAS tokens, pass authentication data with the environmental variables <strong><code>AZURE_STORAGE_ACCOUNT</code></strong> and <strong><code>AZURE_STORAGE_SAS_TOKEN</code></strong>.</p>
<p>It's possible to pass authentication data also as command line arguments: <code>--storage-account</code>, <code>--access-key</code> and <code>--sas-token</code>. This is implemented for those scenarios that don't easily support using environmental variables (e.g. certain scripts); however, it's recommended to use environmental variables whenever possible.</p>
<h3>Arguments</h3><p><strong><code>input</code></strong> is either:</p>
<ul>
<li>The path of a local file to upload (e.g. <code>/path/to/file.jpg</code>)</li>
<li>A dash (<strong><code>-</code></strong>) to read from stdin</li>
</ul>
<p><strong><code>destinationPath</code></strong> is the path inside the Azure Blob Storage account used as destination. It has to start with a slash and include a container name (e.g. <code>/container/path/to/file.jpg</code>). The destination name always has a sequence number automatically appended (e.g. <code>.000</code>, <code>.001</code>, etc), unless the <code>--no-suffix</code> option is passed.</p>
<h3>Options</h3><p>The following command line options are available:</p>
<ul>
<li><strong><code>-b</code></strong> or <strong><code>--blocks</code></strong>: Number of blocks in each blob sent to Azure Blob Storage, each of a fixed size. The maximum (and default) value is 50,000. Setting this to a lower value can lead to more, separate blobs to be created. Because each blob has a performance target of 60MB/s, having your data split into multiple blobs allows for parallel downloads and so potentially faster restores. This has no impact on upload speed, however, as uploads are always sequential.</li>
<li><strong><code>-s</code></strong> or <strong><code>--block-size</code></strong>: Size of each block sent to Azure Blob Storage. The maximum size is 100MB, but the default value is 20MB to reduce memory footprint. Bigger block sizes allow for larger blobs: assuming 50,000 blocks per blob (the default and maximum value), with 100MB-blocks each blob can be up to ~4.8TB, while with 20MB-blocks blobs are limited to ~1TB.</li>
<li><strong><code>-c</code></strong> or <strong><code>--concurrency</code></strong>: Number of chunks to upload in parallel (default is 3). Higher parallelization could help ensuring an efficient use of your Internet connection, but will require more memory.</li>
<li><strong><code>--no-suffix</code></strong>: Upload a single blob only, without appending a numeric suffix to the file name (e.g. <code>.000</code>). Please note that if the file is too big to fit in one blob (as defined by <code>blocks * blockSize</code>), the upload will fail.</li>
<li><strong><code>--endpoint</code></strong>: Endpoint to use. The default value is <code>blob.core.windows.net</code>, which is used by the global Azure infrastructure. Other common values are <code>blob.core.cloudapi.de</code> for Azure Germany and <code>blob.core.chinacloudapi.cn</code> for Azure China. Users of Azure Stack can enter their custom endpoint.</li>
<li><strong><code>--no-md5</code></strong>: Skip calculating MD5 checksums locally before uploading blocks. This can speed up operation on slower systems, but offers no protection against data corruption while in transit.</li>
<li><strong><code>--storage-account</code></strong>: Name of the Azure Storage Account to use. This is an alternative to passing the environmental variable <code>AZURE_STORAGE_ACCOUNT</code>.</li>
<li><strong><code>--access-key</code></strong>: Access Key for the Azure Storage Account to use. This is an alternative to passing the environmental variable <code>AZURE_STORAGE_ACCESS_KEY</code>.</li>
<li><strong><code>--sas-token</code></strong>: SAS Token to use for authentication. This is an alternative to passing the environmental variable <code>AZURE_STORAGE_SAS_TOKEN</code>.</li>
<li><strong><code>-h</code></strong> or <strong><code>--help</code></strong>: Prints help message</li>
<li><strong><code>-V</code></strong> or <strong><code>--version</code></strong>: Prints application version</li>
</ul>
<h3>Examples</h3><p>Set credentials:</p>
<pre class="prettyprint source lang-sh"><code># First method: use export statements (bash syntax)
export AZURE_STORAGE_ACCOUNT=&quot;storageaccountname&quot;
export AZURE_STORAGE_ACCESS_KEY=&quot;abc123&quot;
azbak archive.tar /bak/data01.tar

# Second method: pass arguments inline
AZURE_STORAGE_ACCOUNT=&quot;storageaccountname&quot; AZURE_STORAGE_ACCESS_KEY=&quot;abc123&quot; azbak archive.tar /bak/data01.tar

# Use SAS Tokens
export AZURE_STORAGE_ACCOUNT=&quot;storageaccountname&quot;
export AZURE_STORAGE_SAS_TOKEN=&quot;?sv=...&sig=...&quot;
azbak archive.tar /bak/data01.tar

# Pass authentication data as command line arguments
azbak archive.tar /bak/data01.tar --storage-account &quot;storageaccountname&quot; --sas-token &quot;?sv=...&sig=...&quot;</code></pre><p>Upload file from local disk:</p>
<pre class="prettyprint source lang-sh"><code># Upload file archive.tar to Azure Blob Storage, named &quot;path/data01.tar&quot; inside the Storage Account &quot;bak&quot;
azbak archive.tar /bak/path/data01.tar</code></pre><p>Stream from stdin:</p>
<pre class="prettyprint source lang-sh"><code># Syntax
azbak - /container/file-from-stdin.tar

# Example: gzip file and upload
cat largefile.dat | gzip | azbak - /bak/largefile.dat.gz</code></pre><h1>Library</h1><h2>Installation</h2><p>azbak requires Node.js version 4.0 or higher and NPM.</p>
<p>You can install the package from NPM:</p>
<pre class="prettyprint source lang-sh"><code>npm install --save azbak</code></pre><h2>Usage</h2><p>You can use azbak as a library for other Node.js applications.</p>
<p>Example code:</p>
<pre class="prettyprint source lang-js"><code>const StreamUpload = require('azbak')

// Authentication data
let authData = {
    storageAccountName: storageAccountName,
    storageAccountKey: storageAccountKey,
    // If using SAS token, instead of storageAccountKey use:
    //storageAccountSasToken: storageAccountSasToken
}

// Create the StreamUpload object
let upload = new StreamUpload(sourceStream, destinationPath, authData)

// Pass options
upload.blockSize = 10 * 1024 * 1024

// Start upload
let uploadPromise = upload.upload()

// uploadPromise is a then-able
uploadPromise.then((urls) => {
    // List of blobs uploaded
    console.log(urls)
}, (err) => {
    // In case of errors
    console.log('Upload failed: ', err)
})</code></pre><p>Full API documentation is available in the <a href="docs">/docs</a> folder.</p>
<h1>Docker</h1><p>This utility is available as a Docker container too, published on Docker Hub on <a href="https://hub.docker.com/r/italypaleale/azbak/">italypaleale/azbak</a> You can pass data to be uploaded via stdin, or by mounting a local volume. Examples:</p>
<pre class="prettyprint source lang-sh"><code># Uploading a file from stdin
# Note the -i flag for docker run
# We also need to explicitly specify the &quot;azbak&quot; binary, or docker run will assume &quot;-&quot; is the executable
# You can pass any argument to azbak as if it were to be installed locally
cat archive.tar | docker run \
  --rm \
  -i \
  italypaleale/azbak \
    azbak - /container/archive.tar \
      --storage-account &quot;storageaccountname&quot; \
      --access-key &quot;abc123&quot;

# Same as above, but passing credentials as environmental variables
cat archive.tar | docker run \
  --rm \
  -i \
  -e &quot;AZURE_STORAGE_ACCOUNT=storageaccountname&quot; \
  -e &quot;AZURE_STORAGE_ACCESS_KEY=abc123&quot; \
  italypaleale/azbak \
    azbak - /container/archive.tar

# Mounting a local volume to upload a file from disk (test.jpg from the current folder)
docker run \
  --rm \
  -v &quot;${PWD}/test.jpg:/tmp/test.jpg&quot; \
  -e &quot;AZURE_STORAGE_ACCOUNT=storageaccountname&quot; \
  -e &quot;AZURE_STORAGE_ACCESS_KEY=abc123&quot; \
  italypaleale/azbak \
    azbak /tmp/test.jpg /container/test.jpg</code></pre></article>
    </section>






</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="Authorization.html">Authorization</a></li><li><a href="StreamUpload.html">StreamUpload</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.5.5</a>
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>